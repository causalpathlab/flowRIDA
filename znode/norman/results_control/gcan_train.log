2024-12-26 09:23:25 INFO     Starting training...
2024-12-26 09:23:25 INFO     {'device': 'cuda', 'input_dim': 5000, 'latent_dim': 15, 'layers': [200, 100, 50, 15], 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 128}
2024-12-26 09:23:25 INFO     ETM(
  (encoder): ETMEncoder(
    (fc): Stacklayers(
      (layers): ModuleList(
        (0): Linear(in_features=5000, out_features=200, bias=True)
        (1): ReLU()
        (2): Linear(in_features=200, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=50, bias=True)
        (5): ReLU()
        (6): Linear(in_features=50, out_features=15, bias=True)
        (7): ReLU()
      )
    )
    (z_mean): Linear(in_features=15, out_features=15, bias=True)
    (z_lnvar): Linear(in_features=15, out_features=15, bias=True)
  )
  (decoder): ETMDecoder(
    (lsmax): LogSoftmax(dim=-1)
  )
)
2024-12-26 09:23:25 INFO     Starting training....
2024-12-26 09:23:27 INFO     ====> Epoch: 0 Average loss: 3946.5542
2024-12-26 09:23:37 INFO     ====> Epoch: 10 Average loss: 3316.8947
2024-12-26 09:23:46 INFO     ====> Epoch: 20 Average loss: 3135.8787
2024-12-26 09:23:56 INFO     ====> Epoch: 30 Average loss: 3085.6086
2024-12-26 09:24:05 INFO     ====> Epoch: 40 Average loss: 3061.2506
2024-12-26 09:24:14 INFO     ====> Epoch: 50 Average loss: 3049.0481
2024-12-26 09:24:24 INFO     ====> Epoch: 60 Average loss: 3039.7067
2024-12-26 09:24:33 INFO     ====> Epoch: 70 Average loss: 3034.6628
2024-12-26 09:24:43 INFO     ====> Epoch: 80 Average loss: 3029.0295
2024-12-26 09:24:52 INFO     ====> Epoch: 90 Average loss: 3026.6532
2024-12-26 09:25:02 INFO     ====> Epoch: 100 Average loss: 3023.5564
2024-12-26 09:25:11 INFO     ====> Epoch: 110 Average loss: 3020.5817
2024-12-26 09:25:21 INFO     ====> Epoch: 120 Average loss: 3017.7765
2024-12-26 09:25:30 INFO     ====> Epoch: 130 Average loss: 3016.2016
2024-12-26 09:25:39 INFO     ====> Epoch: 140 Average loss: 3013.8352
2024-12-26 09:25:49 INFO     ====> Epoch: 150 Average loss: 3012.1997
2024-12-26 09:25:58 INFO     ====> Epoch: 160 Average loss: 3010.5818
2024-12-26 09:26:08 INFO     ====> Epoch: 170 Average loss: 3009.9528
2024-12-26 09:26:17 INFO     ====> Epoch: 180 Average loss: 3008.6025
2024-12-26 09:26:27 INFO     ====> Epoch: 190 Average loss: 3007.8273
2024-12-26 09:26:36 INFO     ====> Epoch: 200 Average loss: 3007.3385
2024-12-26 09:26:46 INFO     ====> Epoch: 210 Average loss: 3006.8469
2024-12-26 09:26:55 INFO     ====> Epoch: 220 Average loss: 3006.1714
2024-12-26 09:27:04 INFO     ====> Epoch: 230 Average loss: 3005.7487
2024-12-26 09:27:14 INFO     ====> Epoch: 240 Average loss: 3004.9645
2024-12-26 09:27:23 INFO     ====> Epoch: 250 Average loss: 3005.3694
2024-12-26 09:27:33 INFO     ====> Epoch: 260 Average loss: 3004.7716
2024-12-26 09:27:42 INFO     ====> Epoch: 270 Average loss: 3003.7998
2024-12-26 09:27:52 INFO     ====> Epoch: 280 Average loss: 3004.0998
2024-12-26 09:28:01 INFO     ====> Epoch: 290 Average loss: 3003.0988
2024-12-26 09:28:10 INFO     ====> Epoch: 300 Average loss: 3003.6111
2024-12-26 09:28:20 INFO     ====> Epoch: 310 Average loss: 3003.7997
2024-12-26 09:28:29 INFO     ====> Epoch: 320 Average loss: 3004.1495
2024-12-26 09:28:39 INFO     ====> Epoch: 330 Average loss: 3002.8437
2024-12-26 09:28:48 INFO     ====> Epoch: 340 Average loss: 3002.9010
2024-12-26 09:28:58 INFO     ====> Epoch: 350 Average loss: 3002.4500
2024-12-26 09:29:07 INFO     ====> Epoch: 360 Average loss: 3003.2513
2024-12-26 09:29:17 INFO     ====> Epoch: 370 Average loss: 3001.9939
2024-12-26 09:29:26 INFO     ====> Epoch: 380 Average loss: 3001.0968
2024-12-26 09:29:35 INFO     ====> Epoch: 390 Average loss: 3001.6817
2024-12-26 09:29:45 INFO     ====> Epoch: 400 Average loss: 3001.2842
2024-12-26 09:29:54 INFO     ====> Epoch: 410 Average loss: 3002.1885
2024-12-26 09:30:04 INFO     ====> Epoch: 420 Average loss: 3000.6855
2024-12-26 09:30:13 INFO     ====> Epoch: 430 Average loss: 3000.5890
2024-12-26 09:30:23 INFO     ====> Epoch: 440 Average loss: 3000.4110
2024-12-26 09:30:32 INFO     ====> Epoch: 450 Average loss: 3000.9553
2024-12-26 09:30:41 INFO     ====> Epoch: 460 Average loss: 3000.3811
2024-12-26 09:30:51 INFO     ====> Epoch: 470 Average loss: 3000.6201
2024-12-26 09:31:00 INFO     ====> Epoch: 480 Average loss: 3000.1135
2024-12-26 09:31:10 INFO     ====> Epoch: 490 Average loss: 3000.2352
2024-12-26 09:31:19 INFO     ====> Epoch: 500 Average loss: 3000.4689
2024-12-26 09:31:28 INFO     ====> Epoch: 510 Average loss: 3000.3574
2024-12-26 09:31:38 INFO     ====> Epoch: 520 Average loss: 3000.5006
2024-12-26 09:31:47 INFO     ====> Epoch: 530 Average loss: 3000.0046
2024-12-26 09:31:57 INFO     ====> Epoch: 540 Average loss: 2999.6915
2024-12-26 09:32:06 INFO     ====> Epoch: 550 Average loss: 2999.6271
2024-12-26 09:32:15 INFO     ====> Epoch: 560 Average loss: 2999.4046
2024-12-26 09:32:25 INFO     ====> Epoch: 570 Average loss: 2999.5658
2024-12-26 09:32:34 INFO     ====> Epoch: 580 Average loss: 2999.1395
2024-12-26 09:32:44 INFO     ====> Epoch: 590 Average loss: 2999.0431
2024-12-26 09:32:53 INFO     ====> Epoch: 600 Average loss: 2999.5951
2024-12-26 09:33:02 INFO     ====> Epoch: 610 Average loss: 2999.1625
2024-12-26 09:33:12 INFO     ====> Epoch: 620 Average loss: 2999.0193
2024-12-26 09:33:21 INFO     ====> Epoch: 630 Average loss: 2999.0017
2024-12-26 09:33:31 INFO     ====> Epoch: 640 Average loss: 2998.8345
2024-12-26 09:33:40 INFO     ====> Epoch: 650 Average loss: 2998.7208
2024-12-26 09:33:49 INFO     ====> Epoch: 660 Average loss: 2998.8165
2024-12-26 09:33:59 INFO     ====> Epoch: 670 Average loss: 2998.6700
2024-12-26 09:34:08 INFO     ====> Epoch: 680 Average loss: 2998.3645
2024-12-26 09:34:17 INFO     ====> Epoch: 690 Average loss: 2998.3812
2024-12-26 09:34:27 INFO     ====> Epoch: 700 Average loss: 2998.3352
2024-12-26 09:34:36 INFO     ====> Epoch: 710 Average loss: 2998.4709
2024-12-26 09:34:46 INFO     ====> Epoch: 720 Average loss: 2998.6452
2024-12-26 09:34:55 INFO     ====> Epoch: 730 Average loss: 2998.5404
2024-12-26 09:35:04 INFO     ====> Epoch: 740 Average loss: 2998.2788
2024-12-26 09:35:14 INFO     ====> Epoch: 750 Average loss: 2999.3547
2024-12-26 09:35:23 INFO     ====> Epoch: 760 Average loss: 2998.9866
2024-12-26 09:35:32 INFO     ====> Epoch: 770 Average loss: 2998.0294
2024-12-26 09:35:42 INFO     ====> Epoch: 780 Average loss: 2998.8264
2024-12-26 09:35:51 INFO     ====> Epoch: 790 Average loss: 2998.0427
2024-12-26 09:36:00 INFO     ====> Epoch: 800 Average loss: 2998.6259
2024-12-26 09:36:10 INFO     ====> Epoch: 810 Average loss: 2998.3457
2024-12-26 09:36:19 INFO     ====> Epoch: 820 Average loss: 2998.6542
2024-12-26 09:36:29 INFO     ====> Epoch: 830 Average loss: 2998.2987
2024-12-26 09:36:38 INFO     ====> Epoch: 840 Average loss: 2998.4188
2024-12-26 09:36:48 INFO     ====> Epoch: 850 Average loss: 2998.2221
2024-12-26 09:36:57 INFO     ====> Epoch: 860 Average loss: 2997.9568
2024-12-26 09:37:06 INFO     ====> Epoch: 870 Average loss: 2998.2881
2024-12-26 09:37:15 INFO     ====> Epoch: 880 Average loss: 2997.8656
2024-12-26 09:37:25 INFO     ====> Epoch: 890 Average loss: 2998.8506
2024-12-26 09:37:34 INFO     ====> Epoch: 900 Average loss: 2998.0642
2024-12-26 09:37:43 INFO     ====> Epoch: 910 Average loss: 2997.9331
2024-12-26 09:37:53 INFO     ====> Epoch: 920 Average loss: 2998.1587
2024-12-26 09:38:02 INFO     ====> Epoch: 930 Average loss: 2996.8205
2024-12-26 09:38:11 INFO     ====> Epoch: 940 Average loss: 2997.5458
2024-12-26 09:38:21 INFO     ====> Epoch: 950 Average loss: 2997.8739
2024-12-26 09:38:30 INFO     ====> Epoch: 960 Average loss: 2997.8962
2024-12-26 09:38:40 INFO     ====> Epoch: 970 Average loss: 2997.2945
2024-12-26 09:38:49 INFO     ====> Epoch: 980 Average loss: 2997.3204
2024-12-26 09:38:58 INFO     ====> Epoch: 990 Average loss: 2998.0232
2024-12-26 09:39:07 INFO     Completed training...model saved in results/nn_gcan.model
2024-12-26 09:39:07 INFO     Starting eval...
2024-12-26 09:39:07 INFO     {'device': 'cuda', 'input_dim': 5000, 'latent_dim': 15, 'layers': [200, 100, 50, 15], 'learning_rate': 0.001, 'epochs': 1000, 'batch_size': 128}
2024-12-26 09:39:07 INFO     ETM(
  (encoder): ETMEncoder(
    (fc): Stacklayers(
      (layers): ModuleList(
        (0): Linear(in_features=5000, out_features=200, bias=True)
        (1): ReLU()
        (2): Linear(in_features=200, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=50, bias=True)
        (5): ReLU()
        (6): Linear(in_features=50, out_features=15, bias=True)
        (7): ReLU()
      )
    )
    (z_mean): Linear(in_features=15, out_features=15, bias=True)
    (z_lnvar): Linear(in_features=15, out_features=15, bias=True)
  )
  (decoder): ETMDecoder(
    (lsmax): LogSoftmax(dim=-1)
  )
)
